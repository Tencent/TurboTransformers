We show ALBERT inference performance here.

### GPU
We choose [PyTorch](https://github.com/huggingface "pytorch"), implementation as a comparison. The performance test result is the average of 150 iterations.

* RTX 2060
<img width="900" height="300" src="../images/AlbertSpeedup.jpg" alt="aalbert-2060加速">
<img width="900" height="300" src="../images/albertperf.jpg" alt="aalbert-2060加速">
